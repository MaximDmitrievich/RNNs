{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классические LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.Sequential()\n",
    "# Добавим слой Embedding ожидая на входе словарь размера 1000, и\n",
    "# на выходе вложение размерностью 64.\n",
    "lstm.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Добавим слой LSTM с 128 внутренними узлами.\n",
    "lstm.add(layers.LSTM(128))\n",
    "\n",
    "# Добавим слой Dense с 10 узлами и активацией softmax.\n",
    "lstm.add(layers.Dense(10))\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU = tf.keras.Sequential()\n",
    "GRU.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Выходом GRU будет 3D тензор размера (batch_size, timesteps, 256)\n",
    "GRU.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# Выходом SimpleRNN будет 2D тензор размера (batch_size, 128)\n",
    "GRU.add(layers.SimpleRNN(128))\n",
    "\n",
    "GRU.add(layers.Dense(10))\n",
    "\n",
    "GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None, ))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "\n",
    "# Возвращает состояния в добавление к выходным данным\n",
    "output, state_h, state_c = layers.LSTM(\n",
    "    64, return_state=True, name='encoder')(encoder_embedded)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None, ))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "# Передает 2 состояния в новый слой LSTM в качестве начального состояния\n",
    "decoder_output = layers.LSTM(\n",
    "    64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "\n",
    "lstm_2 = tf.keras.Model([encoder_input, decoder_input], output)\n",
    "lstm_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кросс-пакетное сохранение состояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "for s in sub_sequences:\n",
    "    output = lstm_layer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "\n",
    "# reset_states() сбосит кешированное состояние до изначального initial_state.\n",
    "# Если initial_state не было задано, по умолчанию будут использованы нулевые состояния.\n",
    "lstm_layer.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Двунаправленные RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), \n",
    "                               input_shape=(5, 10)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптмимзация производительности и ядра CuDNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Каждый пакет изображений MNIST это тензор размерностью (batch_size, 28, 28).\n",
    "# Каждая входная последовательность размера (28, 28) (высота рассматривается как время).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # метки от 0 до 9\n",
    "\n",
    "# Построим RNN модель\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "  # CuDNN доступен только на уровне слоя, а не на уровне ячейки.\n",
    "  # Это значит `LSTM(units)` будет использовать ядро CuDNN,\n",
    "  # тогда как RNN(LSTMCell(units)) будет использовать non-CuDNN ядро.\n",
    "    if allow_cudnn_kernel:\n",
    "        # Слой LSTM с параметрами по умолчанию использует CuDNN.\n",
    "        lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Обертка LSTMCell слоем RNN не будет использовать CuDNN.\n",
    "        lstm_layer = tf.keras.layers.RNN(\n",
    "            tf.keras.layers.LSTMCell(units),\n",
    "            input_shape=(None, input_dim))\n",
    "        model = tf.keras.models.Sequential([\n",
    "          lstm_layer,\n",
    "          tf.keras.layers.BatchNormalization(),\n",
    "          tf.keras.layers.Dense(output_size)]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример с MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Новая модель без CuDDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_model = build_model(allow_cudnn_kernel=False)\n",
    "slow_model.set_weights(model.get_weights())\n",
    "slow_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                   optimizer='sgd', \n",
    "                   metrics=['accuracy'])\n",
    "slow_model.fit(x_train, y_train, \n",
    "               validation_data=(x_test, y_test), \n",
    "               batch_size=batch_size,\n",
    "               epochs=1)  # Обучим только за одну эпоху потому что она медленная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
